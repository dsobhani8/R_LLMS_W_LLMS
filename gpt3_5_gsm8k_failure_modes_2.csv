Index,Failure Mode,Description
1,Complex Mathematical Calculations Failure,"GPT-3 sometimes fails to perform complex calculations that are broken down into multiple steps. It may often answer simple mathematics or correctly execute one step of a multi-step problem, but tends to make errors when the problem spans multiple sentences with different instructions. Questions such as the ones about the company's salary expenses over three months, or the total number of goals in a soccer match, or the total number of cookies Randy has, or the time it takes Richard to set off soda fountains, could be challenging for the model because they each necessitate multiple steps of calculations linked together, potentially leading to calculation errors or misunderstandings of what is being asked for in the total."
2,Misinterpretation of Problem Scenarios,"GPT-3 can sometimes misinterpret the context or misunderstand the specifics of a problem scenario. This could include nuances in the wording or specified conditions that alter the nature of the question. This has been observed in questions about Jane's beanstalk, the leftovers for Sam from the fence, or the actions taken in the case of Marcus' homework. These errors occur when the model overlooks some part of the context, perhaps due to an overemphasis or misplaced focus on other parts of the question."
3,Heightened Sequential Reasoning Difficulty,"GPT-3 struggles with questions that require sequential reasoning or logically following a trail of cause and effect. It can properly handle one or two events in a sequence, but fails to maintain consistency when the sequences become more complex and long. Lines of sequential events such as the actions taken by the teacher with the chalk, or the changes in the amount and flavour of cookies, or the decreasing number of balls that Josh juggles, or Brendan's dropping and misidentification of marbles, demand a careful application of sequential rules and the model's failure in these cases underlines its limitations in this aspect."
4,Failure Mode in Tracking Variables and Dynamic Situations,"GPT-3 can struggle to track variables accurately when the situation is dynamic and requires the variables to be updated throughout the problem-solving process. For instance, the adding or subtracting from totals as observed in the buying and baking of cookies, changes in number of marbles, or seats needed for Alex's event indicates that the model could find it challenging to consistently track variables in dynamic situations."
5,Failing to Understand Proportional Relationships,"GPT-3 sometimes struggles to understand or accurately calculate problems that involve proportional relationships, ratios, or percentage-related problems. Questions about the percentage chance that Marcus will have to turn in his homework, or percentage change in the electric bill, or buying discount packages are often incorrectly answered, implying that the model has a problem in this type of calculations."
6,Stumbling Over Time Scales and Unit Conversions,"GPT-3 sometimes seems confused when presented with different time scales and required unit conversions. Questions about transitions between minutes, hours, days, or weeks, or converting gallons to pints can trip up the AI, suggesting a limitation in understanding and correctly applying unit conversions."
7,Issues with Text Parsing in Mathematical Operations,"GPT-3 may interpret some words as indicators of certain mathematical operations, often leading to errors. For example, the word 'less' can be misinterpreted as subtraction even in contexts where it doesn't apply, adding unnecessary complexity and resulting in wrong conclusions. Questions like the distribution of fence feet between Sam and Harry, or the division or addition of workers' salaries, or calculations involving money indicate this failure mode."
8,Difficulty with Age & Time Passage Problems,"Age and time passage problems are often based on simultaneous changes in multiple variables, which seems particularly challenging for GPT-3. It sometimes struggles to correctly apply the passage of time on people's ages or quantities. Questions involving ages of siblings, time of sighting Comet Halley, or calculating daily saving amounts manifest evidence of this failure mode."
9,Problems with Non-linear Sequences or Pattern Recognition,"GPT-3 also has difficulty with non-linear sequences or pattern recognition where the progression is not constant or regular. For example, problems where the avocado tree produces a varying amount of fruits each year, or the beanstalk grows non-linearly, or the changes in how many marbles Brendan ends up with, demonstrate the AI's limitation in accurately recognizing and predicting such patterns."
10,Incorrect Interpretation of Probability,"GPT-3 has been observed to incorrectly interpret probability situations, particularly when these involve conditional probabilities or multiple events influencing the probabilities. Marcus' chance of needing to turn in his homework, or the chance that a baby wearing a bow is wearing purple are examples where the model failed to correctly understand or calculate the probability - it either failed to account for all variables affecting the final outcome or miscalculated the intersection of the events."
