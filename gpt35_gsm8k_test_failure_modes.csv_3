Index,Failure Mode,Description
1,"Complex Mathematical Calculations:** The AI model occasionally struggles with computations involving multiple operations or sequential calculations. For instance, in the questions, ""A company's HR hires 20 new employees every month to add to its total workforce..."" or ""Jane planted a beanstalk in her backyard..."", the calculations are multi-step and require the model to employ a sequenced approach, which it may falter at. The AI should carry out each step, track the result, and apply it to subsequent calculations accurately, a process that can lead to errors.",
2,"Inferring Information from Comparative Statements:** Questions that involve ranking or comparing quantities can create misunderstandings in the model's interpretations. For example, in the question, ""Sam and Harry have 100 feet of fence between them, and they agree to split it with Harry getting 60 feet more than Sam..."", the phrasing implicitly requires knowing that Harry and Sam's portions should add up to 100 feet, but the model could misinterpret this due to its complex sentence structure.",
3,"Time-bound Challenges:** The model seems to have difficulty when dealing with questions that involve the passage of time or interval-based problems. For instance, ""Last month, Tasha made $80...""; ""A teacher uses a 5-inch piece of chalk...""; or ""Josh decides to take up juggling..."" involve compounding over the course of time. Due to the complexity of these formulations, the model might not correctly sequence the events or appropriately perform accumulative calculations.",
4,"Probability Calculations:** Questions that involve percentages and chances like ""Marcus is trying to decide whether he really needs to do his homework..."" may mislead the model. The AI may fail to correctly apply probability rules when calculating independent events, which requires a thorough understanding of probability principles.",
5,"Implicit Conditionals in the Question:** Some questions contain underlying conditions that the model may fail to account for. For example, in the question, ""...Charlie wants to sell beeswax candles..."", there are cost-effectiveness determinations and break-even points associated with profit calculation. The model may neglect these subtle points, leading to errors.",
6,"Complex Word Problems Involving Multiplication and Division:** These questions convert real-life scenarios into mathematical relationships that require multiplication or division, such as, ""...The Llesis family drove and hiked 6 hours to their vacation spot."" The model may have issues accurately translating these scenarios into numerical setups and then carrying out the necessary arithmetic operations. This could be due to the complexity or ambiguity in wording, or the need for critical interpretation skills, which the model lacks.",
7,"Interpretation of Verbs Denoting Increase or Decrease:** Questions like the one about the beanstalk growing or one with a teacher using chalk could mislead the model because they involve changes in size over time, which requires an understanding of the implications of verbs denoting growth or decline. The model may mistakenly treat these changes as static conditions.",
8,"Simultaneous Equations and Variable Allocation:** When questions like, ""I am three years younger than my brother, and I am 2 years older than my sister..."" require setting up and solving simultaneous equations, the model may struggle. This could be due to managing multiple unknowns, correctly linking the variables to their corresponding values, and accurately solving the equations.",
9,"Non-linear Reasoning:** Some problems involve non-linear changes â€“ for example, the height of the beanstalk doubling each day. This kind of exponential growth may confuse the model, which could lead to a linear extrapolation error.",
10,"Reading Comprehension and Contextual Understanding:** The model may fail with contextual cues that involve understanding the semantics behind phrases or sentences, leading to the wrong interpretation of the problem. For instance, Marcus may convince his teacher that his dog ate his homework, requires an understanding of common human excuse stereotypes to accurately assess the scenario. Such figurative language or idioms could confuse the AI model, leading to incorrect answers.",
11,Incomplete Information Nested Problem,"GPT-3.5 can cope well with multiple steps and can deal with information presented out of order, but it struggles if some pieces of information are not explicitly provided. For example, in questions centered around pizzas for four friends, voltage problem, or divided utensils in groups, GPT-3.5 may fail to provide the correct answer due to the lack of explicit linkage between different pieces of information."
12,Interpretation of Vague or Ambiguous Terms,"The model shows limitations in interpreting ambiguous or unclear statements. For example, when determining 'how long it takes for Tom to get back' if his ship sails at 10 miles per hour from 1 to 4 PM and then returns at a rate of 6 mph, the naval distance and the return journey times are unclear."
13,Understanding Financial Concepts,"There seems to be a difficulty comprehending financial principles like interest rates, depreciation, profit and loss calculations, discounts, etc. This is evident in questions like 'Ben bought a car for $20000 in 2007. The price of the car depreciates...'. The language model may not fully understand the mechanism of how the value of a car depreciates over time."
14,Failure Mode,"Interpretation of Collective Action**: For questions like ""Chase and Rider can ride their bikes thrice a day for they ride twice the times..."" where multiple actors perform similar actions may confuse the model due to lack of clarity on whether the actions are performed collectively or individually."
