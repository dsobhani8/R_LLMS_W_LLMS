Index,Failure Mode,Description
1,Multi-Step Computation Error,"This failure mode involves questions that require multiple steps or stages of computation or reasoning to arrive at the correct answer. GPT-3 may fail to complete all necessary steps, or it might perform steps in an incorrect order, leading to incorrect answers. For instance, in the question ""A king gets a crown made that costs $20,000. He tips the person 10%. How much did the king pay after the tip?"", GPT-3 is expected to first calculate the tip amount (2000) and then add it to the initial cost to get the total amount paid."
2,Difficulty with Complex Ratio and Proportion,"Questions involving complex ratios often lead to errors due to GPT-3's difficulty in comprehending and processing the intricacies of proportional relationships. This is a limitation especially in scaling up or down the ratio in a complex manner. For example, in the question ""Brittany, Alex, and Jamy all share 600 marbles divided between them in the ratio 3:5:7. If Brittany gives Alex half of her marbles, what's the total number of marbles that Alex has?"", correctly answering requires understanding of the proportional relationships and the correct apportioning and redistribution of quantities."
3,Complex Time Based Calculations,"GPT-3 tends to make errors when asked about complex calculations involving time, speed, and distance. An example is ""A superhero can use superhuman speed to run 10 miles in 4 minutes. The supervillain has an Evil-Mobile that drives 100 miles per hour. How many miles farther can the superhero run in an hour than the supervillain can drive?"" This type of question requires converting time units and calculating speeds, a task where GPT-3 may fail."
4,Errors in Hypothetical or Future Predictions,"GPT-3 can struggle with questions that inquire about hypothetical future events or require it to predict outcomes based on information provided. The failure here is often due to incorrect interpretation of the conditional scenarios described in these types of questions. For example, ""In five years, Grant will be 2/3 the age of the hospital that he is hired into. If Grant is currently 25 years old, how old is the hospital now?"" requires understanding a future relationship to determine present values."
5,Misinterpretation of Numbers in Language-based Context,"GPT-3 sometimes struggles to correctly interpret numerical values in specific linguistic contexts. The question ""Jan's three-eyed lizard has 3 times more wrinkles than eyes, and seven times more spots than wrinkles. How many fewer eyes does the lizard have than the combined number of spots and wrinkles?"" is a clear example. The linguistic context might make it hard for GPT-3 to correctly identify and handle the numerical values involved."
6,Errors in Tracking Multiple Entities and their Properties,"When a question involves multiple entities (like people or items) and assigns various properties or values to them, GPT-3 can mix up these properties or fail to accurately track which entity each property pertains to. For instance, ""Cindy had 20 marbles which is 5 more than what Lisa had. If Cindy gave her 12 marbles, how many more marbles does Lisa have now?"" requires accurately tracking the marbles associated with Cindy and Lisa."
7,Misunderstanding Fractions and Percentages,"Questions involving fractions or percentages can sometimes lead to errors in GPT-3's responses. This failure mode stems from the GPT-3's understanding and computation of fractional and percentage values. For instance, in the question ""Out of the 400 emails that Antonia received in her mail, 1/4 were spam emails, while 2/5 of the remaining emails were promotional messages. If the rest of the emails were important emails, calculate the total number of important emails in her inbox"", one needs to compute the fraction of a fraction, which GPT-3 could possibly stumble upon."
8,Difficulty in Handling Multi-layered Conditional Scenarios,"Some questions present situational evidence that include multiple cases or conditions, which GPT-3 can struggle to appropriately handle. The questions ""Caroline has 40 pairs of socks. She loses 4 pairs of socks at the laundromat. Of the remaining pairs of socks, she donates two-thirds to the thrift store. Then she purchases 10 new pairs of socks, and she receives 3 new pairs of socks as a gift from her dad. How many pairs of socks does Caroline have in total?"" exemplifies such multi-layered conditions.

Each of these identified failure modes could serve as a basis for further testing GPT-3's performance and enhancing its question-answering capabilities."
9,Formulation of Algebraic Equations,"Some of the questions require the setting up of algebraic equations, based on the information provided, to solve the problem. The model seems to fumble with this abstract representation of problems. For example, in the question ""Five less than three times the number of Doberman puppies plus the difference between the number of Doberman puppies and the number of Schnauzers is equal to 90. If the number of Doberman puppies is 20, how many Schnauzers are there?"", the model might fail to correctly convert the problem into a solvable equation."
10,Comprehensive Profit-Cost Analysis Failure Mode,"Some questions require the model to perform a comprehensive analysis of costs and profits to arrive at the correct response. The model may fail to make the correct calculations or may miss out on some crucial pieces of information, leading to errors. One such example question is ""The cost of building a certain house in an area is 100,000 more than the construction cost of each of the houses in the area.  But it sells for 1.5 times as much as the other houses, which sell at $320,000 each. How much more profit is made by spending the extra money to build?"" Here the model needs to not only compute financial data but also understand the relationship between cost, selling price, and profit."
11,Failure Mode - Comparable and Relational Errors,"This involves the misinterpretation of comparative or relational statements in questions. For instance, interpreting the ""more than"", ""less than"", ""as much as"" relationships in questions like Uncle Jude’s cookie distribution or Reese's piano practice schedule."
12,Imprecise or Vague Language,"The use of imprecise or vague language in questions can lead to incorrect answers as the model may fail to understand the implied specificity due to the nature of its training. Examples include terms like ""next,"" ""then,"" etc. which can create a relative timeline."
13,Assumption of Facts Failure,"Some questions tend to test the model's ability to assume typical everyday facts or realities unpresented within the problem. For instance, ""Max watches a show every day that airs from 2:00 pm to 2:30 pm and only airs during weekdays. If he watches every episode during the week but misses the Friday episode, how many hours of the show did he watch?"" This test requires the assumption of a typical 5-day weekday structure which is not explicitly stated. While this seems natural for human comprehension, the model may fail to make this inference."
14,Sequence and Pattern Recognition,"The model may falter when dealing with problems that involve recognizing and applying number patterns or sequences. For instance, in the problem where the basketball team takes chocolate cookies in an arithmetic sequence, the model must identify and apply this pattern to solve the problem."
15,Currency Exchanges and Monetary Computations,"Some questions involve currency calculations, discounts, taxes or exchange rates which may trip up the AI. The model should understand and apply these monetary concepts correctly to real-world scenarios, as seen in Josie's grocery shopping or James’ purchases with sales taxes."
16,Scientific Knowledge,"Some problems demand knowledge outside pure maths, in particular scientific concepts, like the density or specific properties of substances. For instance, understanding that one ounce of soap makes a certain number of bubbles or knowing how to compute the amount of pure alcohol."
