Index,Failure Mode,Description
1,Failure Mode,"Processing complex mathematical computations**: In situations where multiple operations and conversion of units are necessary, such as rate/time/distance problems or problems involving percentages and fractions, GPT-3.5 may find it challenging. This seems more prevalent when the intermediate steps need to be maintained over several sentences. Examples include the question about John's parent visits and the distance he travels each month, or the question about the school custodian's time spent cleaning classrooms."
2,Failure Mode,"Misinterpretation of Sequential or Chronological Events**: Questions which involve the sequencing of events within a time frame or specific order seem to throw off GPT-3.5, especially when these sequences are involved in the calculation of a final answer. An example is the question about Kim's sleepwalking and how many minutes she slept on a given day."
3,Failure Mode,"Keeping track of relations in people-based problems**: In problems involving relationships between people, such as age comparisons or relating one person's actions to another's, GPT-3.5 may struggle on complex scenarios. This can be seen in problems like Liam’s age compared to Vince’s, or the sequence of betting on horse races described in the question about Johnny's dad."
4,Failure Mode,"Handling semantic ambiguities**: Ambiguity in language can cause problems, especially when a certain phrase or term can have multiple valid interpretations. For instance, the question about Manny's Karate classes could be interpreted differently based on whether the ""cost per class"" refers to the cost Manny pays or what his parents are willing to pay for each class he attends."
5,Failure Mode,"Understanding Conceptual Dependencies**: GPT-3.5 may find it hard to manage dependencies that require understanding the implications of certain states or conditions on subsequent events. For instance, the question with the scenario where Milo is making snowballs that melt as he builds requires an integration of several different aspects and events."
6,Failure Mode,"Money-Related Problems Involving Discounts, Increases, or Compounded Operations**: GPT-3.5 seems to have difficulty with questions involving complex transactions, such as those including discounts, percentage increases, or calculations that need to be compounded over a certain period. Questions about Bill's streaming service subscription, the price of Daniel's school supplies, or Sylvie's salary adjustment are good examples of this."
7,Failure Mode,"Recognizing Indirect Information or Implied Elements**: When a question includes indirect or implied information that isn't explicitly stated but is necessary for the correct answer, GPT-3.5 may not process such subtleties correctly. For example, in the question about Mandy's box of sweets, understanding that each friend gets the same amount of sweets relies on the implication of fairness which may not be explicitly recognized by GPT-3.5."
8,Assumption of Uniform Distribution,"The AI model often assumes distributions are uniform when they are not explicitly stated. Like in the question where Bob distributes $27000 between 3 schools, GPT-3.5 may incorrectly assume the distribution is equal across the schools, which isn't explicitly stated."
9,Comprehension of Relative Terms and Time-Based Calculations,"AI often misunderstands relative time terms such as ""before,"" ""after,"" or ""in-between."" The reference point for these terms isn't always clear in context, and this became evident in the question that asked how long it would take for Mark's beanstalk to be taller than his window."
10,Real-world or Common Knowledge Absence,"The AI model lacks real-world knowledge or makes incorrect assumptions based on common knowledge. For example, in the question regarding how tall the cheerleading pyramid would be, the AI might incorrectly assume each cheerleader fits directly on top of the other by not considering real-world conditions like bending knees, posture or the human body's flexibility."
11,Inference from Complex Scenarios,"The model may fail to extract the relevant information needed to answer the question from complex scenarios, especially when it involves conditional statements or indirect inferences. For example, In the question ""Although Soledad works in a windowless office, she loves the outdoors. She will be on vacation for the entire month of June and cannot wait to hike 9,300 miles within that month. She is thinking of walking twice a day, covering 125 miles each time. How many more miles per day must Soledad hike to complete her journey on time?"" there is an implied condition about how much Soledad needs to cover each day which the model may not fully comprehend."
12,Percentage and Proportional Calculations,"Questions that involve percentage increase/decrease or proportional calculations can prove challenging for the model, for example when trying to calculate tips on a dinner bill or the depreciation of a car. This requires understanding of percentage math which can be a limitation of the model's current abilities."
13,Subtext or Contextual Understanding,"Some questions require understanding of societal or contextual underpinnings not expressed in the text. The model, lacking real-world experiences, may fail these. For instance, understanding that homework doesn't necessarily need to be turned in if there's a substitute teacher."
